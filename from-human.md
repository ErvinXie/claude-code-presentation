使用 claude code 是我今年感觉最幸运的一键事情。claude code 给我带来的震撼不亚于，甚至超过当前 ChatGPT 3.5 给我带来的感觉。我从 8 月开始用 claude code，到现在可能才不到 2 个月，但是我使用它做了非常多的项目，每一个都是我之前完全不敢想的。包括系统级代码编写，到运维，到小工具和管理工作。claude code 带来了全新的 agent 范式，它让 AI 能够和人站在信息的同一起跑线上。充分发挥现代 AI 的智能，而每月 200 美元的订阅费在我看来是给我占了一个非常巨大的便宜。我甚至认为，一个正常水平的研究生可以使用 claude code 接五份远程实习实现月入五万。


总体上讲，限制人类工作效率的关键，在于人类的输入和输出能力非常慢。我们打字的output tps 比 AI 要慢许多，说话的 tps 可能和 AI 相当，但是人类的优势在 RL 的效率远远快于 AI。因此，人类和 AI 最高效率的工作范式，是 AI 处理大量的背景信息，人类根据环境获取新的 feedback 或者 idea，更新到 AI 的背景信息或者规则之中。claude code 基于命令行和文件系统工作，因此它能获取到的背景信息非常多，因此非常适合和人类一起工作。

根据这些原则，我这里展现几个我真实的 claude code 的使用 case，展现它带来的无与伦比的效率提升。

Case1：迅速看代码，找关键实现。
这里以 sglang 代码库为例，我的任务是需要找到awq量化的某种 swizzle 格式，排列是怎么排列的。awq 是一种常见的大语言模型量化格式，它通过把矩阵变成 4bit 来减少模型大小。在它生成的权重里，它并不是按照行主序或者列主序来生成的，而是按照某种 swizzle 顺序排布权重的。由于论文中它语焉不详，所以只能通过代码来确认它是如何解包的。这个过程非常快，只需要几分钟，如果没有 AI 的辅助，在不熟悉 sglang 代码的情况下，可能需要几个小时的工作时间。 

Case2：通过给足背景信息，实现系统级的高性能代码。
我们需要在 KTransformers 中支持 awq 的格式。awq 是一种有 group 分割的量化方式。group size = 64 的意思是在矩阵乘法的 K 维度上每 64 个元素就要把 int4 乘法的结果乘上 scale 变成浮点数。而之前 kt 只支持 perchannel 的量化格式，per channel 是指，在 k 维度只有最后才需要乘上 scale 变成浮点数。他们的区别在于有没有对 K 进行分块。对 K 进行分块就意味着需要对矩阵进行更高维的切分和 pack，这一般是比较难写的。但是最终的结果是，我使用 claude code，通过让他先写测试，之后仿照原有的方案慢慢修改，做出来一个基本运行良好的框架。然后袁子为同学经过两天的调试，发现它某个小的 avx 指令写错了，然后就成功了。将项目周期基本从两周缩短到 2 天。

Case3：完全 vide coding 实现 GPU 监控中心的部署。
在公司有许多 GPU 集群需要管理，而测试和开发许多时候需要使用 gpu 就会产生抢占。此外，gpu 作为重要的资源，也确实是需要有某个方案能够比较好地监控起来。我之前是只知道 node exporter 和 grafana 能够比较好的做到监控。然后我上网查了一下，发现还是确实 NVIDIA 也有类似的 dcgm exporter 来监控 gpu 的使用量。于是我通过 claude code 整了一套部署脚本，能够自动化的远端部署监控的 docker，并且收集的监控中心，解决了这个问题。并且还是用 claude code 写了一个独有的 dashboard 来聚合不同机器的 gpu 使用情况。使用 claude code 我花了大概四个小时完成这个系统（主要用来解决各种 docker 源 pull 不了，依赖装不好的情况），而如果没有 claude code，估计需要花个两三天的时间来折腾。

Case4: 各种立项文档的编写
比如之前 KTransformers 课题和华为合作立项的编写，之前的使用 gpt 需要各种复制粘贴，但是现在确实不需要了。把背景资料和模版文档放到一个目录里面，然后用 claude code 转成 md 方便它读取，然后生成一个 md 格式的项目书。在 md 这个层面调整好所有的信息，然后复制粘贴到 doc 里面。使用 claude code 几乎把这种写文档的工作变得非常快，并且完全无痛。

Case5: 自动化管理
在趋境这边我在做一些项目管理的工作，由于管理的项目众多，所以需要各种对接和同步，并且需要有向上汇报的需求。我使用 claude code 建立了一套自动化的进度更新系统，并且能够自动生成日报和周报。这个非常快的加快了我的效率。


使用的一些问题，现在claude code 调用模型的上下文还是比较短，一般是几百 k 这个级别。几百 k 的级别如果开发比较大项目，可能一个特性改完就会用完 Context，然后需要重新加载信息。这个有许多方法可以解决，一个是让 claude code 写许多文档，或者隔一段时间就让 claude code 把整个项目重构一下。我认为这个是未来需要解决的一个问题，并且这个问题我觉得比较难以通过扩展上下文窗口解决。因为长上下文窗口带来的成本提升实在是太大了。

总体上讲，任何需要快速的信息处理和输出的都可以使用 claude code 来代劳，而我们只需要思考整个流程有哪些需要优化的地方。感谢 claude code，解放了我，也希望未来它能解放更多的人。


确实有一个需要直面的问题，就是 claude code 的价格确实比较高。每月 200 美元的订阅费，对于个人用户来说确实是一个不小的负担。对于公司用户来说，如果能够通过 claude code 带来更高的效率提升，还是值得的。并且在国内缺乏合适的支付手段，目前我个人是使用一些跨境支付机构来支付。然后和同学一起拼单来降低成本。
claude code 除了接入 athoripic 官方的模型之外，还可以接入 glm4.6 和 kimi-k2，glm4.6 是一个开源的模型，并且相对于 k2 模型尺寸小很多。glm4.6 的价格就比 200 美元/月要便宜许多，只需 60 元/季度。我个人感觉 glm4.6 日常使用基本没有问题。glm 系列在大模型 function call 榜单上一直分数都挺高的，比如 bfcl 这种甚至是第一名。如果认为 claude 的价格太贵，可以考虑用 glm4.6 来替代。

此外有一些比较抽象的思考，我认为 claude code 证明了 AI 的能力不完全是由基模决定的。claude code 这种框架本身也构成了 AI 能力的一部分。未来 AI 的能力会越来越多的依赖于它的工作范式，而不仅仅是大模型本身的能力。前面也提到 Context length 现在是一个主要的限制，因此多 agent 系统等等会成为未来的一个趋势。而现在 claude code 本身已经开始使用多 agent 的方式来工作了。haiku 4.5 发布之后，看代码。工作已经完全是用子 agent 来实现的了。

claude code 对程序员的效率本身提升就很大，这个会对整个开发的组织形式产生影响。 claude code 增加了程序员技能的广度，程序员的分工会更加从需求出发而不是从技能出发，会更向产品经理靠拢。一个例子是现在像 FAE （现场应用工程师） 这种角色会越来越重要，因为 FAE 能够更好的理解客户的需求，并且把需求转化成 AI 能够处理的形式。此外，现在 claude code 整处于一个爆发的阶段，这两月我周围从只有一个人使用 claude code，变成了许许多多人使用 claude code，但是其实大家潜意识还没有意识到所有人都在使用 code agent。当使用 code agent 变成一个共识，那么下一步的变革就会开始。
